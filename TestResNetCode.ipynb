{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "cemtukqX4BD3",
        "outputId": "2f0001a1-c3e7-473c-9926-f64d190a4509"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from utils import get_imagenet_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xSRFobZzxor1"
      },
      "outputs": [],
      "source": [
        "# create mask to correspond between imagenet-a labels and imagenet-1k\n",
        "\n",
        "all_wnids, imagenet_a_wnids, imagenet_a_mask = get_imagenet_classes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Mh0T_RL4yDrY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 917 files belonging to 200 classes.\n"
          ]
        }
      ],
      "source": [
        "# drive mount / link to directory\n",
        "\n",
        "val_dir1 = \"C:/Users/laure/Documents/nat_advs_proj/imagenet-a-split/test\"\n",
        "\n",
        "#load val/test to keras dataset from directory provided\n",
        "# the image labels are stored as integers according to the folder names and the \n",
        "# ordering provided by imagenet_a_wnids\n",
        "batch_size = 32\n",
        "val_dataset1 = tf.keras.preprocessing.image_dataset_from_directory(val_dir1, labels='inferred',batch_size=None, label_mode=\"categorical\",\n",
        "                                                                    shuffle=False, class_names = imagenet_a_wnids)\n",
        "image_labels = np.array([y for x, y in val_dataset1])\n",
        "\n",
        "\n",
        "# preprocessing randomly crops to 224x224 and standard ResNet processing is applied\n",
        "def preproc(tensor,y):\n",
        "    tensor = tf.image.random_crop(value=tensor, size=(224,224, 3))\n",
        "    tensor = preprocess_input(tensor)\n",
        "    return tensor, y\n",
        "\n",
        "normalized_ds = val_dataset1.map(preproc).batch(32)\n",
        "\n",
        "#load resnet50 with imagenet-1k weights\n",
        "base_model = ResNet50(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=None,\n",
        "             pooling='avg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_predictions(dset, net=None, mask=None):\n",
        "\n",
        "    # predict labels based on network\n",
        "    outputs = net.predict(dset)\n",
        "\n",
        "    # mask outputs to only be imagenet-a related\n",
        "    mask_outputs = outputs[:,mask]\n",
        "    \n",
        "    # take argmax of the imagenet-a related labels ONLY\n",
        "    pred = np.argmax(mask_outputs,axis=1)\n",
        "\n",
        "    # compare to real labels\n",
        "    num_correct = np.array(pred==image_labels).sum()\n",
        "\n",
        "    #output correct examples\n",
        "    correct = np.argwhere(pred==image_labels)\n",
        "    \n",
        "    return correct, num_correct\n",
        "\n",
        "\n",
        "def get_imagenet_a_results(loader, net, mask):\n",
        "    correct, num_correct = get_predictions(loader, net, mask)\n",
        "    acc = num_correct / image_labels.shape[0]\n",
        "    print('Accuracy (%):', round(100*acc, 4))\n",
        "\n",
        "    return correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step\n",
            "Accuracy (%): 5.8888\n"
          ]
        }
      ],
      "source": [
        "correct_labs = get_imagenet_a_results(normalized_ds, base_model, imagenet_a_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  7],\n",
              "       [122],\n",
              "       [230],\n",
              "       [259],\n",
              "       [281],\n",
              "       [302],\n",
              "       [334],\n",
              "       [351],\n",
              "       [420],\n",
              "       [479],\n",
              "       [511],\n",
              "       [520],\n",
              "       [528],\n",
              "       [536],\n",
              "       [542],\n",
              "       [549],\n",
              "       [557],\n",
              "       [558],\n",
              "       [566],\n",
              "       [588],\n",
              "       [597],\n",
              "       [599],\n",
              "       [612],\n",
              "       [613],\n",
              "       [627],\n",
              "       [646],\n",
              "       [649],\n",
              "       [650],\n",
              "       [654],\n",
              "       [669],\n",
              "       [676],\n",
              "       [677],\n",
              "       [686],\n",
              "       [701],\n",
              "       [717],\n",
              "       [718],\n",
              "       [722],\n",
              "       [731],\n",
              "       [753],\n",
              "       [755],\n",
              "       [765],\n",
              "       [774],\n",
              "       [784],\n",
              "       [786],\n",
              "       [827],\n",
              "       [843],\n",
              "       [850],\n",
              "       [851],\n",
              "       [877],\n",
              "       [882],\n",
              "       [894],\n",
              "       [906],\n",
              "       [907],\n",
              "       [912]], dtype=int64)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# list of correctly predicted examples\n",
        "correct_labs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
